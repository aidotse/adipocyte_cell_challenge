{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hackaton evaluation metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we provide the functions that are used to calculate the quantitative evaluation metric for each magnification in the data set. The overall workflow for one magnification set is given by\n",
    "\n",
    "<img src=\"evaluation_pipe_line.PNG\" align=\"center\" />\n",
    "\n",
    "![evaluation_pipe_line](evaluation_pipe_line.PNG)\n",
    "\n",
    "where the python code is provided in this notebook. The quantitative evaluation metric used to assess the hackathon contributions is divided into two parts: The images are compared using the mean absolute error (MAE) between generated and ground truth images using 1) features extracted by the CellProfiler and 2) pixel values. These are combined by averaging. \n",
    "\n",
    "The evaluation suite in this notebook will be run on each magnification seperately and the final metric is given by the weighted average\n",
    "\\begin{equation*}\n",
    "\\mathrm{MAE}_\\mathrm{tot} = \\frac{1}{n_\\mathrm{tot} }\\left( n_{20x}\\mathrm{MAE}_{20x} +  n_{40x}\\mathrm{MAE}_{40x} +  n_{60x}\\mathrm{MAE}_{60x} \\right)\n",
    "\\end{equation*}\n",
    "\n",
    "where $n_\\mathrm{tot}$ and $n_{20x}/n_{40x}/n_{60x}$ is the number of images in the total and $20x/40x/60x$ data set respectively. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we give the functions that underlie the calculation of each metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import re \n",
    "\n",
    "def get_featurewise_mean_absolute_error(targ_file, pred_file):\n",
    "    \"\"\"The relative mean absolute error between two data sets. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    targ_file : str\n",
    "        Path to csv file containing the CellProfiler results for ground truth images\n",
    "        \n",
    "    pred_file : str\n",
    "        Path to csv file containing the CellProfiler results for generated  images\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    mae_per_feature : array\n",
    "        Mean absolute error (mae) for each feature in the dataset. Each feature-mae is normalized \n",
    "        with the corresponding feature median to account for different feature scales. \n",
    "    \n",
    "    mae : float64\n",
    "        Averaged mae_per_feature\n",
    "    \n",
    "    feature_names : object\n",
    "        names of features in data set\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # read the results into dataframes \n",
    "    df_targ = pd.read_csv(targ_file) \n",
    "    df_pred = pd.read_csv(pred_file)\n",
    "    df_targ = df_targ.drop(['Metadata_Well', 'ImageNumber','Metadata_FoV'], axis=1) # drop metadata\n",
    "    df_pred = df_pred.drop(['Metadata_Well', 'ImageNumber','Metadata_FoV'], axis=1) # drop metadata\n",
    "    n_features = len(df_pred.columns) \n",
    "    feature_names = df_targ.keys()\n",
    "    \n",
    "    # feature normalization \n",
    "    median_targ = df_targ.median()\n",
    "    df_targ = df_targ/median_targ\n",
    "    df_pred = df_pred/median_targ\n",
    "\n",
    "    # mean absolute error for each normalized feature \n",
    "    mae_per_feature = mean_absolute_error(df_pred, df_targ, multioutput='raw_values')\n",
    "    \n",
    "    # Take average of the mean absolute errors \n",
    "    mae = np.average(mae_per_feature)\n",
    "    return mae, mae_per_feature, feature_names\n",
    "\n",
    "\n",
    "def convert_images_to_array(image_dir):\n",
    "    \"\"\"Convert images in directory to numpy arrays \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_dir : str\n",
    "        Path to image directory. The directory must contain n image triplets \n",
    "        with the following naming convention\n",
    "        AssayPlate_Greiner_#655090_D02_T0001F007L01A01Z01C01.tif\n",
    "        AssayPlate_Greiner_#655090_D02_T0001F007L01A01Z01C02.tif\n",
    "        AssayPlate_Greiner_#655090_D02_T0001F007L01A01Z01C03.tif\n",
    "        representing the three target channels for each well and field of view.\n",
    "\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    y_c01 : array\n",
    "        Array containing n C01 images. Shape: (n, image width, image height) \n",
    "    \n",
    "    y_c02 : array\n",
    "        Array containing n C02 images. Shape: (n, image width, image height) \n",
    "    \n",
    "    y_c03 : array\n",
    "        Array containing n C03 images. Shape: (n, image width, image height) \n",
    "        \n",
    "    \"\"\"\n",
    "    # dataframe to store metadata for each file \n",
    "    df = pd.DataFrame(columns = ['path', 'pos', 'F', 'C', 'Z']) \n",
    "    df_row = pd.DataFrame(np.array([[0,0,0,0,0]]), columns = ['path', 'pos', 'F', 'C', 'Z']) \n",
    "\n",
    "    # get all files in image_dir\n",
    "    for x in os.walk(image_dir):\n",
    "        file_list = glob.glob(x[0] + '/AssayPlate*.tif')\n",
    "\n",
    "    # get metadata from each file name and store in df\n",
    "    for file in file_list:\n",
    "        filename = os.path.split(file)[1]\n",
    "        df_row['path'] = file\n",
    "        df_row['pos'] = re.search(r'.\\d\\d_T',filename).group()[0:3]\n",
    "        df_row['F'] = re.search(r'\\dF\\d\\d\\d',filename).group()[1:]\n",
    "        df_row['C'] = re.search(r'\\dC\\d\\d',filename).group()[1:]\n",
    "        df_row['Z'] = re.search(r'\\dZ\\d\\d',filename).group()[1:]\n",
    "        df = df.append(df_row, sort=False)\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # group dataframe according to pos (well) and F (field of view)\n",
    "    df_grouped = df.groupby(['pos','F'])\n",
    "\n",
    "    # empty lists to store images for each flouresence channel\n",
    "    y_c01 = []\n",
    "    y_c02 = []\n",
    "    y_c03 = []\n",
    "\n",
    "    # for every group, load image from each channel  \n",
    "    for state, frame in df_grouped:\n",
    "        frame = frame.sort_values(by=['C','Z'])\n",
    "        for row_index, row in frame.iterrows():\n",
    "            if row['C'] == 'C01':\n",
    "                im = plt.imread(row['path'])\n",
    "                y_c01.append(im)\n",
    "            elif row['C'] == 'C02':\n",
    "                im = plt.imread(row['path'])\n",
    "                y_c02.append(im)\n",
    "            elif row['C'] == 'C03':\n",
    "                im = plt.imread(row['path'])\n",
    "                y_c03.append(im)\n",
    "\n",
    "    # convert to numpy array\n",
    "    y_c01 = np.array(y_c01)\n",
    "    y_c02 = np.array(y_c02)\n",
    "    y_c03 = np.array(y_c03)\n",
    "\n",
    "    return y_c01, y_c02, y_c03\n",
    "\n",
    "def get_pixelwise_mean_absolute_error(targ_dir, pred_dir):\n",
    "    \"\"\"Pixelwise realative mean absolute error between two image data sets\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    target_dir : str\n",
    "        Path to image directory containing ground truth images.\n",
    "    \n",
    "    pred_dir : str\n",
    "        Path to image directory containing generated images. T\n",
    "        \n",
    "    Both directories must contain n image triplets with the \n",
    "    following naming convention\n",
    "    AssayPlate_Greiner_#655090_D02_T0001F007L01A01Z01C01.tif\n",
    "    AssayPlate_Greiner_#655090_D02_T0001F007L01A01Z01C02.tif\n",
    "    AssayPlate_Greiner_#655090_D02_T0001F007L01A01Z01C03.tif\n",
    "    representing the three target channels for each well and field of view.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    mae_c01 : float64\n",
    "        Pixel-to-pixel relative mean absolute error for channel C01 \n",
    "    \n",
    "    mae_c02 : float64\n",
    "        Pixel-to-pixel relative mean absolute error for channel C02 \n",
    "    \n",
    "    mae_c03 : float64\n",
    "        Pixel-to-pixel relative mean  absolute error for channel C03\n",
    "    \n",
    "    mae : float64\n",
    "        Average of mae_c01, mae_c02 and mae_c03\n",
    "    \"\"\"\n",
    "    # convert target images to array\n",
    "    y_c01_targ, y_c02_targ, y_c03_targ = convert_images_to_array(targ_dir)\n",
    "    # convert predicted images to array\n",
    "    y_c01_pred, y_c02_pred, y_c03_pred = convert_images_to_array(pred_dir)\n",
    "    \n",
    "    # calculate mae between target and predicted images\n",
    "    # mae is normalized to the target median \n",
    "    mae_c01 = mean_absolute_error(y_c01_targ.flatten(), y_c01_pred.flatten())/np.median(y_c01_targ)\n",
    "    mae_c02 = mean_absolute_error(y_c02_targ.flatten(), y_c02_pred.flatten())/np.median(y_c02_targ)\n",
    "    mae_c03 = mean_absolute_error(y_c03_targ.flatten(), y_c03_pred.flatten())/np.median(y_c03_targ)\n",
    "    \n",
    "    # take average of the mean absolute errors \n",
    "    mae = np.average([mae_c01, mae_c02, mae_c03])\n",
    "    \n",
    "    return mae, mae_c01, mae_c02, mae_c03\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featurewise Mean Absolute Error "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the MAE based on the comparison of image features derived from CellProfiler. Since the image features have different scale the errors are normalized using each respective feature median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targ_file = \"path to csv-file containing result for ground truth images\"\n",
    "pred_file = \"path to csv-file containing result for generated images\"\n",
    "\n",
    "mae_cp, mae_per_feature, feature_names = get_featurewise_mean_absolute_error(targ_file, pred_file)\n",
    "\n",
    "# plot the mean absolute error per normalized feature\n",
    "f, ax = plt.subplots(figsize = (10,5)) \n",
    "ax.set_title('MAE = ' + str(mae_cp) )\n",
    "ax.set_ylabel('relative mean absolute error')\n",
    "ax.plot(mae_per_feature, '-*')\n",
    "ax.grid(True)\n",
    "plt.xticks(np.arange(len(mae_per_feature)), feature_names, rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pixelwise Mean Absolute Error "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the pixel-to-pixel MAE averaged over the three target channels.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "targ_dir = \"path to directory containing ground truth images for all channels, one magnification\"\n",
    "pred_dir = \"path to directory containing generated images for all channels, one magnification\"\n",
    "mae_pix,_,_,_ = get_pixelwise_mean_absolute_error(targ_dir, pred_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_c01, y_c02, y_c03 = convert_images_to_array(targ_dir)\n",
    "\n",
    "image_index = 0 # choose image\n",
    "\n",
    "f, ax = plt.subplots(1, 3, sharey=True, sharex=True, figsize = (40,20)) \n",
    "\n",
    "ax[0].imshow( y_c01[image_index,:,:] )\n",
    "ax[0].set_title('C01',size=20)\n",
    "ax[0].get_xaxis().set_visible(False)\n",
    "ax[0].get_yaxis().set_visible(False)\n",
    "\n",
    "ax[1].imshow( y_c02[image_index,:,:] )\n",
    "ax[1].set_title('C02',size=20)\n",
    "ax[1].get_xaxis().set_visible(False)\n",
    "ax[1].get_yaxis().set_visible(False)\n",
    "\n",
    "ax[2].imshow( y_c03[image_index,:,:] )\n",
    "ax[2].set_title('C03',size=20)\n",
    "ax[2].get_xaxis().set_visible(False)\n",
    "ax[2].get_yaxis().set_visible(False)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final evaluation metric "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The end point metric is given by the average of the CellProfiler and pixel-to-pixel MAEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = np.average([mae_cp, mae_pix])\n",
    "print('Evaluation metric = ' + str(mae))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('tf_conda': conda)",
   "language": "python",
   "name": "python37764bittfcondaconda7dec74c660214c218c908e85f6f019c1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc-showcode": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
